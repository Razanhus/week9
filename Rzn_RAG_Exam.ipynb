{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Razanhus/week9/blob/main/Rzn_RAG_Exam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m83H0SRDK01q"
      },
      "source": [
        "# Traffic Violation RAG System\n",
        "In this exam, you will implement a Retrieval-Augmented Generation (RAG) system that uses a language model and a vector database to answer questions about traffic violations. The goal is to generate answers with relevant data based on a dataset of traffic violations and fines.\n",
        "\n",
        "Here are helpful resources:\n",
        "* [LangChain](https://www.langchain.com/)\n",
        "* [groq cloud documentation](https://console.groq.com/docs/models)\n",
        "* [LangChain HuggingFace](https://python.langchain.com/docs/integrations/text_embedding/sentence_transformers/)\n",
        "* [Chroma Vector Store](https://python.langchain.com/docs/integrations/vectorstores/chroma/)\n",
        "* [Chroma Website](https://docs.trychroma.com/getting-started)\n",
        "* [ChatGroq LangChain](https://python.langchain.com/docs/integrations/chat/groq/)\n",
        "* [LLM Chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html#langchain.chains.llm.LLMChain)\n",
        "\n",
        "Dataset [source](https://www.moi.gov.sa/wps/portal/Home/sectors/publicsecurity/traffic/contents/!ut/p/z0/04_Sj9CPykssy0xPLMnMz0vMAfIjo8ziDTxNTDwMTYy83V0CTQ0cA71d_T1djI0MXA30gxOL9L30o_ArApqSmVVYGOWoH5Wcn1eSWlGiH1FSlJiWlpmsagBlKCQWqRrkJmbmqRqUZebngB2gUJAKdERJZmqxfkG2ezgAhzhSyw!!/)\n",
        "\n",
        "Some installs if needed:\n",
        "```python\n",
        "!pip install langchain_huggingface langchain langchain-community langchain_chroma Chroma langchain_groq LLMChain\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_huggingface langchain langchain-community langchain_chroma Chroma langchain_groq LLMChain"
      ],
      "metadata": {
        "id": "kTreQTVWsD4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v7c12iLur9_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b15a700-25e1-4383-af6f-7246c28f1ece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/khaledzsa/dataset\n",
            "License(s): unknown\n",
            "Downloading dataset.zip to /content\n",
            "  0% 0.00/3.73k [00:00<?, ?B/s]\n",
            "100% 3.73k/3.73k [00:00<00:00, 410kB/s]\n",
            "Archive:  dataset.zip\n",
            "  inflating: Dataset.csv             \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d khaledzsa/dataset\n",
        "!unzip dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKe3G7bqK-W6"
      },
      "source": [
        "## Step 1: Install Required Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewOnaf7BLBQ8"
      },
      "source": [
        "To begin, install the necessary libraries for this project. The libraries include `LangChain` for building language model chains, and `Chroma` for managing a vector database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5oHl_P67_V6m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_community"
      ],
      "metadata": {
        "id": "8BL7nXfQtM9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "HNOL8NUfxDiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "nlVySs_IxX4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq"
      ],
      "metadata": {
        "id": "958MU4rRyMpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings.sentence_transformer import (\n",
        "    SentenceTransformerEmbeddings,\n",
        ")\n",
        "import markdown\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import json\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n"
      ],
      "metadata": {
        "id": "y9JqMnpftRoT"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "VwU1lcSl1xQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI7_KEjILJZ8"
      },
      "source": [
        "# Step 2: Load the Traffic Violations Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY6U8FxlLLON"
      },
      "source": [
        "You are provided with a dataset of traffic violations. Load the CSV file into a pandas DataFrame and preview the first few rows of the dataset using `.head()`. You can also try and see the dataset's characteristics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PzTMfTyJ_tZG"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/Dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "display(df)"
      ],
      "metadata": {
        "id": "5Mxw7zHH1Lej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZSvKjJXssQG",
        "outputId": "e86cfa87-bf52-4273-cf8a-2f6b4cd9d0d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(104, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hs28tz2LbFx"
      },
      "source": [
        "## Step 3: Create Markdown Content from the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiNAqLhELd_S"
      },
      "source": [
        "For each traffic violation in the dataset, you will generate markdown text that describes the violation and the associated fine. Create a loop to iterate through the dataset and store the generated markdown in a list. Each fine should look like this:\n",
        "\n",
        "**المخالفة** - الغرامة"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifkMDS5SLui4"
      },
      "source": [
        "## Step 4: Chunk the Markdown Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJxNEV5yLxMu"
      },
      "source": [
        "Using LangChain's `RecursiveCharacterTextSplitter`, split the markdown texts into smaller chunks that will be stored in the vector database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Hf3-3j9iALUN"
      },
      "outputs": [],
      "source": [
        "directory = 'data/markdown_files'\n",
        "os.makedirs(directory, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(df)):\n",
        "\n",
        "    violation = df['المخالفة'].iloc[i]\n",
        "    fine = df['الغرامة'].iloc[i]\n",
        "\n",
        "    markdown_content = f\"# {violation}\\n\\n\"\n",
        "    markdown_content += f\"{fine}\\n\\n\"\n",
        "\n",
        "    with open(f'{directory}/{i}.md', 'w', encoding='utf-8') as file:\n",
        "        file.write(markdown_content)"
      ],
      "metadata": {
        "id": "glkklYwft7AS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markdown_texts = []\n",
        "for filename in os.listdir(directory):\n",
        "  if filename.endswith(\".md\"):\n",
        "    with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
        "      markdown_content = file.read()\n",
        "      html_content = markdown.markdown(markdown_content)\n",
        "      markdown_texts.append(html_content)"
      ],
      "metadata": {
        "id": "NKx-oVEVuqbP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EviXuMjfL2Gj"
      },
      "source": [
        "## Step 5: Generate Embeddings for the Documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAUq12UtL5OJ"
      },
      "source": [
        "Generate embeddings for the chunks of text using HuggingFace's pre-trained Arabic language model. These embeddings will be stored in a `Chroma` vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "d4-YlqMKAeGr"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
        "documents = text_splitter.create_documents(markdown_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l32elHl2L-ob"
      },
      "source": [
        "# Step 6: Define the RAG Prompt Template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1zWp3KfMAld"
      },
      "source": [
        "Define a custom prompt template in Arabic to retrieve traffic violation-related answers based on the context. Ensure the template encourages the model to give **advice** in **Arabic**, staying within the context provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "gdy4qbn_CYTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ad0794-8ef3-41a4-d1ae-c033cbe9d1c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name aubmindlab/bert-base-arabertv02. Creating a new one with mean pooling.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"aubmindlab/bert-base-arabertv02\")\n",
        "db = Chroma.from_documents(documents, embedding_function, persist_directory=\"./chroma_db\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvfcCIjgMG34"
      },
      "source": [
        "## Step 7: Initialize the Language Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groq_api_key = \"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\"\n",
        "llm = ChatGroq(temperature=0, groq_api_key=groq_api_key, model_name=\"llama3-8b-8192\")"
      ],
      "metadata": {
        "id": "r2ulq52gzz--"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lvHUsNTMIvX"
      },
      "source": [
        "Initialize the language model using the Groq API. Set up the model with a specific configuration, including the API key, temperature setting, and model name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3T-2Fy9MLPa"
      },
      "source": [
        "## Step 8: Create the LLM Chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCcrmiA2MOOi"
      },
      "source": [
        "Now, you will create an LLM Chain that combines the language model and the prompt template you defined. This chain will be used to generate responses based on the retrieved context."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_TEMPLATE = \"\"\"\n",
        "استنادًا إلى المعلومات التالية فقط، قم بالإجابة على السؤال:\n",
        "المعلومات: {context}\n",
        "السؤال: {question}\n",
        "إجابتك:\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    template=PROMPT_TEMPLATE, input_variables=[\"context\",\"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "WH6xJxyH2iEA"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "j1EEjdquHrTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c03cdf12-dc7c-481e-cb24-dd69c42b5f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-a2932d0d6a9b>:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  MODEL = LLMChain(llm=llm,\n"
          ]
        }
      ],
      "source": [
        "MODEL = LLMChain(llm=llm,\n",
        "                 prompt=prompt_template,\n",
        "                 verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di48NYGQMQtS"
      },
      "source": [
        "## Step 9: Implement the Query Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huXN44hwMS07"
      },
      "source": [
        "Create a function `query_rag` that will take a user query as input, retrieve relevant context from the vector store, and use the language model to generate a response based on that context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "HJLrEKqzHhDy"
      },
      "outputs": [],
      "source": [
        "def query_rag(query: str):\n",
        "    similarity_search_results = db.similarity_search_with_score(query, k=4)\n",
        "    context_text = \"\\n\\n\".join([doc.page_content for doc, _score in similarity_search_results])\n",
        "\n",
        "    rag_response = MODEL.invoke({\"context\": context_text, \"question\": query})\n",
        "\n",
        "    return rag_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iRfIjyzPLC_"
      },
      "source": [
        "## Step 10: Inference - Running Queries in the RAG System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iTaUjpWPOyt"
      },
      "source": [
        "In this final step, you will implement an inference pipeline to handle real-time queries. You will allow the system to retrieve the most relevant violations and fines based on a user's input and generate a response.\n",
        "\n",
        "1. Inference Workflow:\n",
        "\n",
        "  * The user inputs a query (e.g., \"ماهي الغرامة على القيادة بدون رخصة؟\").\n",
        "  * The system searches for the most relevant context from the traffic violation vector store.\n",
        "  * It generates an answer and advice based on the context.\n",
        "\n",
        "2. Goal:\n",
        "  * Run the inference to answer questions based on the traffic violation dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inference_pipeline():\n",
        "    user_query = input(\"ايش سؤالك):؟\")\n",
        "    response = query_rag(user_query)\n",
        "    print(\"الجواب:\", response)\n",
        "\n",
        "inference_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzuRf96u8HrP",
        "outputId": "165e3efd-3aee-42a7-cf56-22b6031e3b26"
      },
      "execution_count": 73,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ايش سؤالك):؟ماهي الغرامة على قيادة المركبة قبل الحصول على رخصة؟\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "استنادًا إلى المعلومات التالية فقط، قم بالإجابة على السؤال:\n",
            "المعلومات: <h1>عدم إعطاء أفضلية المرور في ملتقيات الطرق أو تقاطعاتها لسائق المركبة المتقدم على غيره في حال عدم وجود لوحات تنظم ذلك.</h1>\n",
            "<p>الغرامة المالية 500 - 900 ريال</p>\n",
            "\n",
            "<h1>قيادة المركبة برخصة قيادة لا تتناسب مع حجم المركبة ونوع استخدامها.</h1>\n",
            "<p>الغرامة المالية 1000 - 2000 ريال</p>\n",
            "\n",
            "<h1>قيادة المركبة قبل الحصول على رخصة قيادة أو في حال سحب الرخصة.</h1>\n",
            "<p>الغرامة المالية 1000 - 2000 ريال</p>\n",
            "\n",
            "<h1>تسيير مركبات الأشغال العامة على الطرق قبل اتخاذ الإجراءات اللازمة لتلافي أضرارها، بما في ذلك عدم وضع الشرائح العاكسة على جانبي مؤخرة المركبة.</h1>\n",
            "<p>الغرامة المالية 3000 - 6000 ريال</p>\n",
            "السؤال: ماهي الغرامة على قيادة المركبة قبل الحصول على رخصة؟\"\n",
            "إجابتك:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "الجواب: {'context': '<h1>عدم إعطاء أفضلية المرور في ملتقيات الطرق أو تقاطعاتها لسائق المركبة المتقدم على غيره في حال عدم وجود لوحات تنظم ذلك.</h1>\\n<p>الغرامة المالية 500 - 900 ريال</p>\\n\\n<h1>قيادة المركبة برخصة قيادة لا تتناسب مع حجم المركبة ونوع استخدامها.</h1>\\n<p>الغرامة المالية 1000 - 2000 ريال</p>\\n\\n<h1>قيادة المركبة قبل الحصول على رخصة قيادة أو في حال سحب الرخصة.</h1>\\n<p>الغرامة المالية 1000 - 2000 ريال</p>\\n\\n<h1>تسيير مركبات الأشغال العامة على الطرق قبل اتخاذ الإجراءات اللازمة لتلافي أضرارها، بما في ذلك عدم وضع الشرائح العاكسة على جانبي مؤخرة المركبة.</h1>\\n<p>الغرامة المالية 3000 - 6000 ريال</p>', 'question': 'ماهي الغرامة على قيادة المركبة قبل الحصول على رخصة؟\"', 'text': 'الغرامة المالية على قيادة المركبة قبل الحصول على رخصة هي 1000 - 2000 ريال.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "7k4BmIAHH38X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7225b2c3-2c2e-4bfe-c869-bfeb91ed887a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             المخالفة                            الغرامة\n",
            "101  استخدام لوحات غير عائدة للمركبة.  الغرامة المالية 5000 - 10000 ريال\n"
          ]
        }
      ],
      "source": [
        "rows = df[df['المخالفة'] == 'استخدام لوحات غير عائدة للمركبة.']\n",
        "print(rows)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rows = df[df['المخالفة'] == 'سير المركبة بلا لوحة خلفية، أو بلا لوحات.']\n",
        "print(rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFQw_UnO4BWZ",
        "outputId": "018777fb-7eb6-482c-81ba-b2ab6041fda7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     المخالفة  \\\n",
            "96  سير المركبة بلا لوحة خلفية، أو بلا لوحات.   \n",
            "\n",
            "                             الغرامة  \n",
            "96  الغرامة المالية 3000 - 6000 ريال  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_rag(\"ماهي الغرامة على قيادة المركبة قبل الحصول على رخصة؟\")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gzyocnK3gf-",
        "outputId": "d1ef464d-34ea-4ca0-e1d3-fbde093c4e8e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "استنادًا إلى المعلومات التالية فقط، قم بالإجابة على السؤال:\n",
            "المعلومات: <h1>عدم إعطاء أفضلية المرور في ملتقيات الطرق أو تقاطعاتها لسائق المركبة المتقدم على غيره في حال عدم وجود لوحات تنظم ذلك.</h1>\n",
            "<p>الغرامة المالية 500 - 900 ريال</p>\n",
            "\n",
            "<h1>قيادة المركبة قبل الحصول على رخصة قيادة أو في حال سحب الرخصة.</h1>\n",
            "<p>الغرامة المالية 1000 - 2000 ريال</p>\n",
            "\n",
            "<h1>قيادة المركبة برخصة قيادة لا تتناسب مع حجم المركبة ونوع استخدامها.</h1>\n",
            "<p>الغرامة المالية 1000 - 2000 ريال</p>\n",
            "\n",
            "<h1>عدم قيام السائق الذي يرغب في تغيير مساره بإعطاء الأفضلية لسائق المركبة التي تسير في اتجاه مستقيم في حال سير المركبتين متحاذيتين بشكل متواز.</h1>\n",
            "<p>الغرامة المالية 500 - 900 ريال</p>\n",
            "السؤال: ماهي الغرامة على قيادة المركبة قبل الحصول على رخصة؟\n",
            "إجابتك:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': '<h1>عدم إعطاء أفضلية المرور في ملتقيات الطرق أو تقاطعاتها لسائق المركبة المتقدم على غيره في حال عدم وجود لوحات تنظم ذلك.</h1>\\n<p>الغرامة المالية 500 - 900 ريال</p>\\n\\n<h1>قيادة المركبة قبل الحصول على رخصة قيادة أو في حال سحب الرخصة.</h1>\\n<p>الغرامة المالية 1000 - 2000 ريال</p>\\n\\n<h1>قيادة المركبة برخصة قيادة لا تتناسب مع حجم المركبة ونوع استخدامها.</h1>\\n<p>الغرامة المالية 1000 - 2000 ريال</p>\\n\\n<h1>عدم قيام السائق الذي يرغب في تغيير مساره بإعطاء الأفضلية لسائق المركبة التي تسير في اتجاه مستقيم في حال سير المركبتين متحاذيتين بشكل متواز.</h1>\\n<p>الغرامة المالية 500 - 900 ريال</p>',\n",
              " 'question': 'ماهي الغرامة على قيادة المركبة قبل الحصول على رخصة؟',\n",
              " 'text': 'الغرامة المالية 1000 - 2000 ريال.'}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_rag(\"ماهي الغرامة على التجمهر في موقع الحادث؟\")\n",
        "response"
      ],
      "metadata": {
        "id": "l13ToPNZ49LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"ماهي الغرامة على التجمهر في موقع الحادث؟\"\n",
        "similarity_search_results = db.similarity_search_with_score(query, k=4)"
      ],
      "metadata": {
        "id": "yCv9PzZ4-WX5"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First: \", similarity_search_results[0][0].page_content)\n",
        "print(\"Second: \", similarity_search_results[1][0].page_content)\n",
        "print(\"Third: \", similarity_search_results[2][0].page_content)\n",
        "print(\"Fourth: \", similarity_search_results[3][0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT-lzezu-Ey_",
        "outputId": "3e92376a-f832-4f57-a40d-122bfe094586"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First:  <h1>عدم إعطاء الأفضلية للمركبات التي بداخل الدوار من قبل المركبات التي خارجه في حالة عدم وجود إشارات ضوئية أو رجل أمن يوجه السير.</h1>\n",
            "<p>الغرامة المالية 500 - 900 ريال</p>\n",
            "Second:  <h1>قيام السائق بتخطي أرتال المركبات أمام إشارات المرور أو نقاط الضبط الأمني باستخدام كتف الطريق أو المسار المخصص للالتفاف.</h1>\n",
            "<p>الغرامة المالية 150 - 300 ريال</p>\n",
            "Third:  <h1>تركيب تجهيزات في المركبة كتلك الخاصة بالمركبات الرسمية ومركبات الطوارئ.</h1>\n",
            "<p>الغرامة المالية 3000 - 6000 ريال</p>\n",
            "Fourth:  <h1>تسيير مركبات الأشغال العامة على الطرق قبل اتخاذ الإجراءات اللازمة لتلافي أضرارها، بما في ذلك عدم وضع الشرائح العاكسة على جانبي مؤخرة المركبة.</h1>\n",
            "<p>الغرامة المالية 3000 - 6000 ريال</p>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(similarity_search_results[0][1])\n",
        "print(similarity_search_results[1][1])\n",
        "print(similarity_search_results[2][1])\n",
        "print(similarity_search_results[3][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtmEj7ud-Hvw",
        "outputId": "a00d6f31-0f23-4c4a-f5fd-1c6487d93944"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202.95266723632812\n",
            "206.18600463867188\n",
            "207.601806640625\n",
            "208.4356231689453\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}